\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{schmidhuber2015deep}
\citation{Taigman_2014_CVPR}
\citation{Design_Exploration_SbS_Trans20}
\citation{Spinnaker_Trans13}
\citation{ernst2007efficient}
\citation{Design_Exploration_SbS_Trans20}
\citation{SNN_Survey_Trans19}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Accelerating Spike-by-Spike Neural Networks}{19}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Accelerating Spike-by-Spike Neural Networks}{19}{chapter.3}\protected@file@percent }
\@writefile{lot}{\contentsline {xchapter}{Accelerating Spike-by-Spike Neural Networks}{19}{chapter.3}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap.sbs}{{3}{19}{Accelerating Spike-by-Spike Neural Networks}{chapter.3}{}}
\newlabel{chap.sbs@cref}{{[chapter][3][]3}{[1][19][]19}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{19}{section.3.1}\protected@file@percent }
\newlabel{sec:introduction}{{3.1}{19}{Introduction}{section.3.1}{}}
\newlabel{sec:introduction@cref}{{[section][1][3]3.1}{[1][19][]19}}
\@gls@reference{main}{ai}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{19}}
\@gls@reference{main}{ann}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{19}}
\citation{mcdonnell2011benefits}
\citation{ernst2007efficient}
\citation{Dapello2020.06.16.154542}
\citation{davies2018loihi}
\citation{davies2018loihi}
\citation{TrueNorth_Trans15}
\citation{Spinnaker_Trans13}
\citation{izhikevich2004model}
\citation{amunts2019human}
\citation{rotermund2019Backpropagation}
\citation{ernst2007efficient}
\citation{nevarez2020accelerator}
\citation{rotermund2018massively}
\citation{rotermund2019Backpropagation}
\@gls@reference{main}{mlp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{cnn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{ai}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{dnn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{dnn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{lif}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{ann}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{ip_sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{nnmf}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{nn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{nn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\citation{roy2019towards}
\citation{bouvier2019spiking}
\citation{young2019review}
\citation{TrueNorth_Trans15}
\citation{Spinnaker_Trans13}
\citation{davies2018loihi}
\citation{nevarez2020accelerator}
\citation{rotermund2018massively}
\citation{nevarez2020accelerator}
\citation{ernst2007efficient}
\citation{rotermund2019recurrentsbs}
\citation{dayan2001theoretical}
\citation{zhang2018survey}
\citation{lotrivc2012applicability}
\citation{sarwar2016multiplier}
\citation{mrazek2016design}
\citation{du2014leveraging}
\citation{park2009dynamic}
\citation{han2013approximate}
\citation{gupta2011impact}
\citation{mittal2016survey}
\citation{venkataramani2015approximate}
\@gls@reference{main}{cnn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{cnn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{fp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{fp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{fp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{fp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{fp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{qor}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{qor}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{fp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{21}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{22}}
\@gls@reference{main}{fp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{22}}
\@gls@reference{main}{fp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{22}}
\@gls@reference{main}{qor}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{22}}
\@gls@reference{main}{fp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Dot-product hardware module with (a) standard floating-point (IEEE 754) arithmetic, (b) hybrid custom floating-point approximation, and (c) hybrid logarithmic approximation.\relax }}{22}{figure.caption.12}\protected@file@percent }
\newlabel{fig:dot_product_unit}{{3.1}{22}{Dot-product hardware module with (a) standard floating-point (IEEE 754) arithmetic, (b) hybrid custom floating-point approximation, and (c) hybrid logarithmic approximation.\relax }{figure.caption.12}{}}
\newlabel{fig:dot_product_unit@cref}{{[figure][1][3]3.1}{[1][21][]22}}
\citation{bouvier2019spiking}
\citation{courbariaux2015binaryconnect}
\citation{han2015deep}
\citation{hubara2017quantized}
\citation{rastegari2016xnor}
\citation{moons20160}
\citation{whatmough201714}
\citation{rastegari2016xnor}
\citation{sun2018xnor}
\citation{lecun1989optimal}
\citation{hassibi1992second}
\citation{molchanov2016pruning}
\citation{li2016pruning}
\citation{liu2018rethinking}
\citation{rathi2018stdp}
\citation{sen2017approximate}
\citation{srivastava2014dropout}
\citation{wan2013regularization}
\citation{neftci2016stochastic}
\citation{srinivasan2016magnetic}
\citation{buesing2011neural}
\citation{bellec2017deep}
\citation{chen20184096}
\citation{sheik2016synaptic}
\citation{jerry2017ultra}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Related Work}{23}{section.3.2}\protected@file@percent }
\newlabel{sec:related_work}{{3.2}{23}{Related Work}{section.3.2}{}}
\newlabel{sec:related_work@cref}{{[section][2][3]3.2}{[1][23][]23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Network Compression}{23}{subsection.3.2.1}\protected@file@percent }
\@gls@reference{main}{ann}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@gls@reference{main}{wq}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@gls@reference{main}{bnn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@gls@reference{main}{xnor}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@gls@reference{main}{mac}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@gls@reference{main}{bnn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@gls@reference{main}{ann}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@gls@reference{main}{dnn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\citation{zhang2018survey}
\citation{han2013approximate}
\citation{han2013approximate}
\citation{kim2013energy}
\citation{he2016deep}
\citation{russakovsky2015imagenet}
\citation{rastegari2016xnor}
\citation{rotermund2018massively}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@gls@reference{main}{ann}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@gls@reference{main}{ann}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Classical Approximate Computing}{24}{subsection.3.2.2}\protected@file@percent }
\@gls@reference{main}{snn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Spike-by-Spike Neural Networks Accelerators}{24}{subsection.3.2.3}\protected@file@percent }
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@gls@reference{main}{ip_sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@gls@reference{main}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@gls@reference{main}{asic}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{25}}
\@gls@reference{main}{sbs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}System Design}{25}{section.3.3}\protected@file@percent }
\newlabel{sec:system_design}{{3.3}{25}{System Design}{section.3.3}{}}
\newlabel{sec:system_design@cref}{{[section][3][3]3.3}{[1][25][]25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Hardware Architecture}{25}{subsection.3.3.1}\protected@file@percent }
\newlabel{Hardware_architecture}{{3.3.1}{25}{Hardware Architecture}{subsection.3.3.1}{}}
\newlabel{Hardware_architecture@cref}{{[subsection][1][3,3]3.3.1}{[1][25][]25}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces System-level overview of the embedded software architecture.\relax }}{25}{figure.caption.13}\protected@file@percent }
\newlabel{fig:sw_stack}{{3.2}{25}{System-level overview of the embedded software architecture.\relax }{figure.caption.13}{}}
\newlabel{fig:sw_stack@cref}{{[figure][2][3]3.2}{[1][25][]25}}
\citation{rotermund2019Backpropagation}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Conv Processing Unit}{26}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Configuration Mode}{26}{section*.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces System-level hardware architecture with scalable number of heterogeneous PUs: \emph  {Spike}, \emph  {Conv}, \emph  {Pool}, and \emph  {FC}\relax }}{26}{figure.caption.14}\protected@file@percent }
\newlabel{fig:hw_sbs}{{3.3}{26}{System-level hardware architecture with scalable number of heterogeneous PUs: \emph {Spike}, \emph {Conv}, \emph {Pool}, and \emph {FC}\relax }{figure.caption.14}{}}
\newlabel{fig:hw_sbs@cref}{{[figure][3][3]3.3}{[1][26][]26}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Computation Mode}{27}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Dot-Product Hardware Module}{28}{subsection.3.3.3}\protected@file@percent }
\newlabel{sec:dot-product_hardware_module}{{3.3.3}{28}{Dot-Product Hardware Module}{subsection.3.3.3}{}}
\newlabel{sec:dot-product_hardware_module@cref}{{[subsection][3][3,3]3.3.3}{[1][27][]28}}
\newlabel{eq:dot_product}{{3.1}{28}{Dot-Product Hardware Module}{equation.3.3.1}{}}
\newlabel{eq:dot_product@cref}{{[subsection][3][3,3]3.3.3}{[1][28][]28}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The \emph  {Conv} processing unit and its six stages: (a) receive IP vector, (b) spike firing, (c) receive spike kernel, (d) update dynamics, (e) dispatch new IP vector, (f) dispatch output spike matrix.\relax }}{28}{figure.caption.17}\protected@file@percent }
\newlabel{fig:hw_conv}{{3.4}{28}{The \emph {Conv} processing unit and its six stages: (a) receive IP vector, (b) spike firing, (c) receive spike kernel, (d) update dynamics, (e) dispatch new IP vector, (f) dispatch output spike matrix.\relax }{figure.caption.17}{}}
\newlabel{fig:hw_conv@cref}{{[figure][4][3]3.4}{[1][27][]28}}
\newlabel{eq:exp_max}{{3.2}{29}{Dot-Product Hardware Module}{equation.3.3.2}{}}
\newlabel{eq:exp_max@cref}{{[subsection][3][3,3]3.3.3}{[1][29][]29}}
\newlabel{eq:bits_exp}{{3.3}{29}{Dot-Product Hardware Module}{equation.3.3.3}{}}
\newlabel{eq:bits_exp@cref}{{[subsection][3][3,3]3.3.3}{[1][29][]29}}
\newlabel{eq:bits_bitwidth}{{3.4}{29}{Dot-Product Hardware Module}{equation.3.3.4}{}}
\newlabel{eq:bits_bitwidth@cref}{{[subsection][3][3,3]3.3.3}{[1][29][]29}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Dot-Product with Standard Floating-Point Computation}{29}{section*.18}\protected@file@percent }
\newlabel{eq:dot_standard_float_latency}{{3.5}{30}{Dot-Product with Standard Floating-Point Computation}{equation.3.3.5}{}}
\newlabel{eq:dot_standard_float_latency@cref}{{[subsection][3][3,3]3.3.3}{[1][29][]30}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Dot-Product with Hybrid Custom Floating-Point and Logarithmic Approximation}{30}{section*.20}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Dot-product hardware module with standard floating-point (IEEE 754) computation, (a) exhibits the initiation interval of 10 clock cycles, (b) presents the iteration latency of 19 clock cycles, (c) shows the pairwise product block in dark-gray, and (d) illustrates the accumulation block in light-gray.\relax }}{30}{figure.caption.19}\protected@file@percent }
\newlabel{fig:dot_product_float}{{3.5}{30}{Dot-product hardware module with standard floating-point (IEEE 754) computation, (a) exhibits the initiation interval of 10 clock cycles, (b) presents the iteration latency of 19 clock cycles, (c) shows the pairwise product block in dark-gray, and (d) illustrates the accumulation block in light-gray.\relax }{figure.caption.19}{}}
\newlabel{fig:dot_product_float@cref}{{[figure][5][3]3.5}{[1][30][]30}}
\citation{xilinx2015zynq}
\citation{nevarez2020accelerator}
\newlabel{eq:dot_standard_custom_float_latency}{{3.6}{32}{Dot-Product with Hybrid Custom Floating-Point and Logarithmic Approximation}{equation.3.3.6}{}}
\newlabel{eq:dot_standard_custom_float_latency@cref}{{[subsection][3][3,3]3.3.3}{[1][32][]32}}
\newlabel{eq:dot_log_latency}{{3.7}{32}{Dot-Product with Hybrid Custom Floating-Point and Logarithmic Approximation}{equation.3.3.7}{}}
\newlabel{eq:dot_log_latency@cref}{{[subsection][3][3,3]3.3.3}{[1][32][]32}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Experimental Results}{32}{section.3.4}\protected@file@percent }
\newlabel{sec:experimental_results}{{3.4}{32}{Experimental Results}{section.3.4}{}}
\newlabel{sec:experimental_results@cref}{{[section][4][3]3.4}{[1][32][]32}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Dot-product hardware module with hybrid custom floating-point approximation, (a) exhibits the initiation interval of 2 clock cycles, (b) presents the iteration latency of 13 clock cycles, (c) shows the pairwise product blocks in dark-gray, and (d) illustrates the accumulation blocks in light-gray.\relax }}{33}{figure.caption.21}\protected@file@percent }
\newlabel{fig:dot_product_custom}{{3.6}{33}{Dot-product hardware module with hybrid custom floating-point approximation, (a) exhibits the initiation interval of 2 clock cycles, (b) presents the iteration latency of 13 clock cycles, (c) shows the pairwise product blocks in dark-gray, and (d) illustrates the accumulation blocks in light-gray.\relax }{figure.caption.21}{}}
\newlabel{fig:dot_product_custom@cref}{{[figure][6][3]3.6}{[1][32][]33}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Dot-product hardware module with hybrid logarithmic approximation, (a) exhibits the initiation interval of 2 clock cycles, (b) presents the iteration latency of 9 clock cycles, (c) shows the pairwise product block in dark-gray, and (d) illustrates the accumulation blocks in light-gray.\relax }}{33}{figure.caption.22}\protected@file@percent }
\newlabel{fig:dot_product_log}{{3.7}{33}{Dot-product hardware module with hybrid logarithmic approximation, (a) exhibits the initiation interval of 2 clock cycles, (b) presents the iteration latency of 9 clock cycles, (c) shows the pairwise product block in dark-gray, and (d) illustrates the accumulation blocks in light-gray.\relax }{figure.caption.22}{}}
\newlabel{fig:dot_product_log@cref}{{[figure][7][3]3.7}{[1][32][]33}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Computation on embedded CPU.\relax }}{34}{table.caption.24}\protected@file@percent }
\newlabel{tab:latency_sw}{{3.1}{34}{Computation on embedded CPU.\relax }{table.caption.24}{}}
\newlabel{tab:latency_sw@cref}{{[table][1][3]3.1}{[1][34][]34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Performance Benchmark}{34}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Benchmark on Embedded CPU}{34}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Benchmark on Processing Units with Standard Floating-Point Computation}{34}{section*.26}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Performance of processing units with standard floating-point (IEEE 754) computation.\relax }}{35}{table.caption.28}\protected@file@percent }
\newlabel{tab:latency_fp}{{3.2}{35}{Performance of processing units with standard floating-point (IEEE 754) computation.\relax }{table.caption.28}{}}
\newlabel{tab:latency_fp@cref}{{[table][2][3]3.2}{[1][35][]35}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Computation on embedded CPU.\relax }}{35}{figure.caption.25}\protected@file@percent }
\newlabel{fig:latency_sw}{{3.8}{35}{Computation on embedded CPU.\relax }{figure.caption.25}{}}
\newlabel{fig:latency_sw@cref}{{[figure][8][3]3.8}{[1][34][]35}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces System overview of the top-level architecture with 8 processing units.\relax }}{35}{figure.caption.27}\protected@file@percent }
\newlabel{fig:hw_sbs_8_pu}{{3.9}{35}{System overview of the top-level architecture with 8 processing units.\relax }{figure.caption.27}{}}
\newlabel{fig:hw_sbs_8_pu@cref}{{[figure][9][3]3.9}{[1][34][]35}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Performance of processing units with standard floating-point (IEEE 754) computation.\relax }}{36}{figure.caption.29}\protected@file@percent }
\newlabel{fig:latency_pu_fp}{{3.10}{36}{Performance of processing units with standard floating-point (IEEE 754) computation.\relax }{figure.caption.29}{}}
\newlabel{fig:latency_pu_fp@cref}{{[figure][10][3]3.10}{[1][35][]36}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Performance bottleneck of cyclic computation on processing units with standard floating-point (IEEE 754) arithmetic, (a) exhibits the starting of $t_{PU}$ of \emph  {Conv2} on a previous computation cycle, (b) presents $t_{CPU}$ of \emph  {Conv2} on the current computation cycle, (c) shows the CPU waiting time (in gray color) for \emph  {Conv2} as a busy resource (awaiting for \emph  {Conv2} interruption), and (d) illustrates the $t_{f}$ from the previous computation cycle, the starting of $t_{PU}$ on the current computation cycle (\emph  {Conv2} interruption on completion, and start current computation cycle).\relax }}{36}{figure.caption.30}\protected@file@percent }
\newlabel{fig:latency_pu_fp_cycle}{{3.11}{36}{Performance bottleneck of cyclic computation on processing units with standard floating-point (IEEE 754) arithmetic, (a) exhibits the starting of $t_{PU}$ of \emph {Conv2} on a previous computation cycle, (b) presents $t_{CPU}$ of \emph {Conv2} on the current computation cycle, (c) shows the CPU waiting time (in gray color) for \emph {Conv2} as a busy resource (awaiting for \emph {Conv2} interruption), and (d) illustrates the $t_{f}$ from the previous computation cycle, the starting of $t_{PU}$ on the current computation cycle (\emph {Conv2} interruption on completion, and start current computation cycle).\relax }{figure.caption.30}{}}
\newlabel{fig:latency_pu_fp_cycle@cref}{{[figure][11][3]3.11}{[1][36][]36}}
\citation{hrica2012floating}
\newlabel{eq:time_cpu}{{3.8}{37}{Benchmark on Processing Units with Standard Floating-Point Computation}{equation.3.4.8}{}}
\newlabel{eq:time_cpu@cref}{{[subsection][1][3,4]3.4.1}{[1][36][]37}}
\newlabel{eq:time_pu}{{3.9}{37}{Benchmark on Processing Units with Standard Floating-Point Computation}{equation.3.4.9}{}}
\newlabel{eq:time_pu@cref}{{[subsection][1][3,4]3.4.1}{[1][37][]37}}
\newlabel{eq:time_spike}{{3.10}{37}{Benchmark on Processing Units with Standard Floating-Point Computation}{equation.3.4.10}{}}
\newlabel{eq:time_spike@cref}{{[subsection][1][3,4]3.4.1}{[1][37][]37}}
\newlabel{eq:time_finish}{{3.11}{37}{Benchmark on Processing Units with Standard Floating-Point Computation}{equation.3.4.11}{}}
\newlabel{eq:time_finish@cref}{{[subsection][1][3,4]3.4.1}{[1][37][]37}}
\citation{venkataramani2015approximate}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Resource utilization and power dissipation of processing units with standard floating-point (IEEE 754) computation.\relax }}{38}{table.caption.31}\protected@file@percent }
\newlabel{tab:resource_fp}{{3.3}{38}{Resource utilization and power dissipation of processing units with standard floating-point (IEEE 754) computation.\relax }{table.caption.31}{}}
\newlabel{tab:resource_fp@cref}{{[table][3][3]3.3}{[1][37][]38}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Resource utilization and power dissipation of multiplier and adder floating-point (IEEE 754) operator cores.\relax }}{38}{table.caption.32}\protected@file@percent }
\newlabel{tab:LogiCORE}{{3.4}{38}{Resource utilization and power dissipation of multiplier and adder floating-point (IEEE 754) operator cores.\relax }{table.caption.32}{}}
\newlabel{tab:LogiCORE@cref}{{[table][4][3]3.4}{[1][38][]38}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Benchmark on Noise Tolerance Plot}{38}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Design Exploration with Hybrid Custom Floating-Point and Logarithmic Approximation}{39}{subsection.3.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Noise tolerance on hardware PU with standard floating-point (IEEE 754) computation (benchmark/reference), (a) exhibits accuracy degradation applying $50\%$ of noise amplitude, and (b) illustrates convergence of inference with $400$ spikes.\relax }}{39}{figure.caption.34}\protected@file@percent }
\newlabel{fig:accuracy_vs_noise_pu_fp}{{3.12}{39}{Noise tolerance on hardware PU with standard floating-point (IEEE 754) computation (benchmark/reference), (a) exhibits accuracy degradation applying $50\%$ of noise amplitude, and (b) illustrates convergence of inference with $400$ spikes.\relax }{figure.caption.34}{}}
\newlabel{fig:accuracy_vs_noise_pu_fp@cref}{{[figure][12][3]3.12}{[1][39][]39}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Parameters for Numeric Representation of Synaptic Weight Matrix}{40}{section*.35}\protected@file@percent }
\newlabel{sec:parameters}{{3.4.2}{40}{Parameters for Numeric Representation of Synaptic Weight Matrix}{section*.35}{}}
\newlabel{sec:parameters@cref}{{[subsection][2][3,4]3.4.2}{[1][40][]40}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Design Exploration for Dot-product with Hybrid Custom Floating-Point Approximation}{40}{section*.37}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Resource utilization and power dissipation of processing units with hybrid custom floating-point approximation.\relax }}{41}{table.caption.38}\protected@file@percent }
\newlabel{tab:resource_cfp}{{3.5}{41}{Resource utilization and power dissipation of processing units with hybrid custom floating-point approximation.\relax }{table.caption.38}{}}
\newlabel{tab:resource_cfp@cref}{{[table][5][3]3.5}{[1][41][]41}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Design Exploration for Dot-Product whit Hybrid Logarithmic Approximation}{41}{section*.42}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces $\qopname  \relax o{log}_2$-histogram of each synaptic weight matrix showing the percentage of matrix elements with given integer exponent.\relax }}{41}{figure.caption.36}\protected@file@percent }
\newlabel{fig:log2histogram}{{3.13}{41}{$\log _2$-histogram of each synaptic weight matrix showing the percentage of matrix elements with given integer exponent.\relax }{figure.caption.36}{}}
\newlabel{fig:log2histogram@cref}{{[figure][13][3]3.13}{[1][40][]41}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Performance of hardware processing units with hybrid custom floating-point approximation.\relax }}{42}{table.caption.39}\protected@file@percent }
\newlabel{tab:latency_cfp}{{3.6}{42}{Performance of hardware processing units with hybrid custom floating-point approximation.\relax }{table.caption.39}{}}
\newlabel{tab:latency_cfp@cref}{{[table][6][3]3.6}{[1][41][]42}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Performance on processing units with hybrid custom floating-point approximation, (a) exhibits computation schedule, (b) presents cyclic computation schedule, and (c) shows the performance of \emph  {Conv2} from a previous computation cycle during the preprocessing of \emph  {H1\_CONV} on the current computation cycle without bottleneck.\relax }}{42}{figure.caption.40}\protected@file@percent }
\newlabel{fig:latency_pu_cfp_cycle}{{3.14}{42}{Performance on processing units with hybrid custom floating-point approximation, (a) exhibits computation schedule, (b) presents cyclic computation schedule, and (c) shows the performance of \emph {Conv2} from a previous computation cycle during the preprocessing of \emph {H1\_CONV} on the current computation cycle without bottleneck.\relax }{figure.caption.40}{}}
\newlabel{fig:latency_pu_cfp_cycle@cref}{{[figure][14][3]3.14}{[1][41][]42}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Noise tolerance on hardware PU with custom floating-point approximation, (a) exhibits accuracy degradation applying $50\%$ of noise amplitude, and (b) illustrates convergence of inference with $400$ spikes.\relax }}{43}{figure.caption.41}\protected@file@percent }
\newlabel{fig:accuracy_vs_noise_pu_cfp}{{3.15}{43}{Noise tolerance on hardware PU with custom floating-point approximation, (a) exhibits accuracy degradation applying $50\%$ of noise amplitude, and (b) illustrates convergence of inference with $400$ spikes.\relax }{figure.caption.41}{}}
\newlabel{fig:accuracy_vs_noise_pu_cfp@cref}{{[figure][15][3]3.15}{[1][41][]43}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces Performance of hardware processing units with hybrid logarithmic approximation.\relax }}{44}{table.caption.43}\protected@file@percent }
\newlabel{tab:latency_log}{{3.7}{44}{Performance of hardware processing units with hybrid logarithmic approximation.\relax }{table.caption.43}{}}
\newlabel{tab:latency_log@cref}{{[table][7][3]3.7}{[1][43][]44}}
\@writefile{lot}{\contentsline {table}{\numberline {3.8}{\ignorespaces Resource utilization and power dissipation of processing units with hybrid logarithmic approximation.\relax }}{44}{table.caption.45}\protected@file@percent }
\newlabel{tab:resource_log}{{3.8}{44}{Resource utilization and power dissipation of processing units with hybrid logarithmic approximation.\relax }{table.caption.45}{}}
\newlabel{tab:resource_log@cref}{{[table][8][3]3.8}{[1][43][]44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Results and Discussion}{44}{subsection.3.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces Performance of processing units with hybrid logarithmic approximation, (a) exhibits computation schedule, and (b) illustrates cyclic computation schedule.\relax }}{44}{figure.caption.44}\protected@file@percent }
\newlabel{fig:latency_pu_log_cycle}{{3.16}{44}{Performance of processing units with hybrid logarithmic approximation, (a) exhibits computation schedule, and (b) illustrates cyclic computation schedule.\relax }{figure.caption.44}{}}
\newlabel{fig:latency_pu_log_cycle@cref}{{[figure][16][3]3.16}{[1][43][]44}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces Noise tolerance on hardware PU with hybrid logarithmic approximation, (a) exhibits accuracy degradation applying $40\%$ of noise amplitude, (b) illustrates convergence of inference with $600$ spikes.\relax }}{45}{figure.caption.46}\protected@file@percent }
\newlabel{fig:accuracy_vs_noise_pu_log}{{3.17}{45}{Noise tolerance on hardware PU with hybrid logarithmic approximation, (a) exhibits accuracy degradation applying $40\%$ of noise amplitude, (b) illustrates convergence of inference with $600$ spikes.\relax }{figure.caption.46}{}}
\newlabel{fig:accuracy_vs_noise_pu_log@cref}{{[figure][17][3]3.17}{[1][43][]45}}
\@writefile{lot}{\contentsline {table}{\numberline {3.9}{\ignorespaces Experimental results.\relax }}{46}{table.caption.48}\protected@file@percent }
\newlabel{tab:results}{{3.9}{46}{Experimental results.\relax }{table.caption.48}{}}
\newlabel{tab:results@cref}{{[table][9][3]3.9}{[1][46][]46}}
\@writefile{lot}{\contentsline {table}{\numberline {3.10}{\ignorespaces Platform implementations.\relax }}{46}{table.caption.50}\protected@file@percent }
\newlabel{tab:platform_comparison}{{3.10}{46}{Platform implementations.\relax }{table.caption.50}{}}
\newlabel{tab:platform_comparison@cref}{{[table][10][3]3.10}{[1][46][]46}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Conclusions}{47}{section.3.5}\protected@file@percent }
\newlabel{sec:conclusions}{{3.5}{47}{Conclusions}{section.3.5}{}}
\newlabel{sec:conclusions@cref}{{[section][5][3]3.5}{[1][46][]47}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Power dissipation breakdown of platform implementations, (a) \ref  {nevarez2020accelerator} architecture with homogeneous AUs using standard floating-point arithmetic (IEEE 754), (b) reference architecture with specialized heterogeneous PUs using standard floating-point arithmetic (IEEE 754), (c) proposed architecture with hybrid custom floating-point approximation, and (d) proposed architecture with hybrid logarithmic approximation.\relax }}{47}{figure.caption.51}\protected@file@percent }
\newlabel{fig:platform_power_dissipation_breakdown}{{3.18}{47}{Power dissipation breakdown of platform implementations, (a) \ref {nevarez2020accelerator} architecture with homogeneous AUs using standard floating-point arithmetic (IEEE 754), (b) reference architecture with specialized heterogeneous PUs using standard floating-point arithmetic (IEEE 754), (c) proposed architecture with hybrid custom floating-point approximation, and (d) proposed architecture with hybrid logarithmic approximation.\relax }{figure.caption.51}{}}
\newlabel{fig:platform_power_dissipation_breakdown@cref}{{[figure][18][3]3.18}{[1][46][]47}}
\@setckpt{./chapters/accelerating_sbs}{
\setcounter{page}{48}
\setcounter{equation}{11}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{1}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{5}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{18}
\setcounter{table}{10}
\setcounter{Item}{16}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{0}
\setcounter{float@type}{8}
\setcounter{parentequation}{0}
\setcounter{etoc@tocid}{1}
\setcounter{etoc@tocdepth}{4}
\setcounter{lstnumber}{1}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{r@tfl@t}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{mtc}{3}
\setcounter{minitocdepth}{2}
\setcounter{ptc}{0}
\setcounter{parttocdepth}{2}
\setcounter{su@anzahl}{0}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{1}
\setcounter{algocfproc}{1}
\setcounter{algocf}{1}
\setcounter{ALC@unique}{15}
\setcounter{ALC@line}{15}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{theorem}{0}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{section@level}{1}
\setcounter{lstlisting}{0}
\setcounter{minilofdepth}{2}
\setcounter{minilotdepth}{2}
\setcounter{partlofdepth}{2}
\setcounter{partlotdepth}{2}
\setcounter{sectlofdepth}{2}
\setcounter{sectlotdepth}{2}
}
